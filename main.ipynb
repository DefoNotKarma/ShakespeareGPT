{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f4e7d1-f3cb-46d9-8b17-65562c3e1093",
   "metadata": {},
   "source": [
    "<h2>ShakespeareGPT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67602c6-7a09-4fb5-bf25-5d19505433b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a29c7fdab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ipdb\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.set_printoptions(precision=7, sci_mode=False)\n",
    "torch.manual_seed(42128)\n",
    "gen = torch.Generator().manual_seed(42128)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb115f3-43f4-4439-a6cd-0847479eec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(\"input.txt\", 'r', encoding=\"utf-8\").read()\n",
    "special_charas = ['$', '&', '3', '-', ';']\n",
    "\n",
    "# Create a regex pattern to match the special characters\n",
    "pattern = re.compile(f\"[{re.escape(''.join(special_charas))}]\")\n",
    "\n",
    "# Remove the special characters\n",
    "text = pattern.sub('', text)\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6317976b-4614-484a-9799-ad68b453c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1119738"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b23c381-3a30-476f-8659-254f549f48cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n',\n",
       "  ' ',\n",
       "  '!',\n",
       "  \"'\",\n",
       "  ',',\n",
       "  '.',\n",
       "  ':',\n",
       "  '?',\n",
       "  'A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z'],\n",
       " 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chara_list = sorted(set(text))\n",
    "vocab_size = len(chara_list)\n",
    "chara_list, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e3ce91-aec3-4a6f-b475-a700d3168465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'\\n': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  \"'\": 3,\n",
       "  ',': 4,\n",
       "  '.': 5,\n",
       "  ':': 6,\n",
       "  '?': 7,\n",
       "  'A': 8,\n",
       "  'B': 9,\n",
       "  'C': 10,\n",
       "  'D': 11,\n",
       "  'E': 12,\n",
       "  'F': 13,\n",
       "  'G': 14,\n",
       "  'H': 15,\n",
       "  'I': 16,\n",
       "  'J': 17,\n",
       "  'K': 18,\n",
       "  'L': 19,\n",
       "  'M': 20,\n",
       "  'N': 21,\n",
       "  'O': 22,\n",
       "  'P': 23,\n",
       "  'Q': 24,\n",
       "  'R': 25,\n",
       "  'S': 26,\n",
       "  'T': 27,\n",
       "  'U': 28,\n",
       "  'V': 29,\n",
       "  'W': 30,\n",
       "  'X': 31,\n",
       "  'Y': 32,\n",
       "  'Z': 33,\n",
       "  'a': 34,\n",
       "  'b': 35,\n",
       "  'c': 36,\n",
       "  'd': 37,\n",
       "  'e': 38,\n",
       "  'f': 39,\n",
       "  'g': 40,\n",
       "  'h': 41,\n",
       "  'i': 42,\n",
       "  'j': 43,\n",
       "  'k': 44,\n",
       "  'l': 45,\n",
       "  'm': 46,\n",
       "  'n': 47,\n",
       "  'o': 48,\n",
       "  'p': 49,\n",
       "  'q': 50,\n",
       "  'r': 51,\n",
       "  's': 52,\n",
       "  't': 53,\n",
       "  'u': 54,\n",
       "  'v': 55,\n",
       "  'w': 56,\n",
       "  'x': 57,\n",
       "  'y': 58,\n",
       "  'z': 59},\n",
       " {0: '\\n',\n",
       "  1: ' ',\n",
       "  2: '!',\n",
       "  3: \"'\",\n",
       "  4: ',',\n",
       "  5: '.',\n",
       "  6: ':',\n",
       "  7: '?',\n",
       "  8: 'A',\n",
       "  9: 'B',\n",
       "  10: 'C',\n",
       "  11: 'D',\n",
       "  12: 'E',\n",
       "  13: 'F',\n",
       "  14: 'G',\n",
       "  15: 'H',\n",
       "  16: 'I',\n",
       "  17: 'J',\n",
       "  18: 'K',\n",
       "  19: 'L',\n",
       "  20: 'M',\n",
       "  21: 'N',\n",
       "  22: 'O',\n",
       "  23: 'P',\n",
       "  24: 'Q',\n",
       "  25: 'R',\n",
       "  26: 'S',\n",
       "  27: 'T',\n",
       "  28: 'U',\n",
       "  29: 'V',\n",
       "  30: 'W',\n",
       "  31: 'X',\n",
       "  32: 'Y',\n",
       "  33: 'Z',\n",
       "  34: 'a',\n",
       "  35: 'b',\n",
       "  36: 'c',\n",
       "  37: 'd',\n",
       "  38: 'e',\n",
       "  39: 'f',\n",
       "  40: 'g',\n",
       "  41: 'h',\n",
       "  42: 'i',\n",
       "  43: 'j',\n",
       "  44: 'k',\n",
       "  45: 'l',\n",
       "  46: 'm',\n",
       "  47: 'n',\n",
       "  48: 'o',\n",
       "  49: 'p',\n",
       "  50: 'q',\n",
       "  51: 'r',\n",
       "  52: 's',\n",
       "  53: 't',\n",
       "  54: 'u',\n",
       "  55: 'v',\n",
       "  56: 'w',\n",
       "  57: 'x',\n",
       "  58: 'y',\n",
       "  59: 'z'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = {s:i for i, s in enumerate(chara_list)}\n",
    "decoding = {i:s for i, s in enumerate(chara_list)}\n",
    "encoding, decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281efa9f-68f1-49e1-b44d-a901ba720ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda seq: [encoding[letter] for letter in seq]\n",
    "decode = lambda tensor: [''.join(decoding[integer] for integer in tensor)]\n",
    "#encode('hi'), decode([47,38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad27bac9-1c2d-4126-932a-952034c2d2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13, 42, 51, 52, 53,  1, 10, 42, 53, 42, 59, 38, 47,  6,  0,  9, 38, 39,\n",
       "         48, 51, 38,  1, 56, 38,  1, 49, 51, 48, 36, 38, 38, 37,  1, 34, 47, 58,\n",
       "          1, 39, 54, 51, 53, 41, 38, 51,  4,  1, 41, 38, 34, 51,  1, 46, 38,  1,\n",
       "         52, 49, 38, 34, 44,  5,  0,  0,  8, 45, 45,  6,  0, 26, 49, 38, 34, 44,\n",
       "          4,  1, 52, 49, 38, 34, 44,  5,  0,  0, 13, 42, 51, 52, 53,  1, 10, 42,\n",
       "         53, 42, 59, 38, 47,  6,  0, 32, 48, 54]),\n",
       " torch.int64,\n",
       " 1119738)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data[:100], data.dtype, data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6f8536-17a6-446f-9faf-b9c4b71b370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train, val = data[:n], data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c3f6a1-ab5b-44f8-ac66-aeae9b1002f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 128]), torch.Size([5, 128]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "block_size = 128\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split == \" train\" else val\n",
    "    idx = torch.randint(0, data.shape[0] - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx ])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    return x,y\n",
    "\n",
    "x_batch, y_batch = get_batch(\"train\")\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec28b9b-c359-44cb-b6d4-0733e03f0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones((block_size, block_size))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, context, head = x.shape\n",
    "        key_vector = self.key(x)\n",
    "        query_vector = self.query(x)\n",
    "        value_vector = self.value(x)\n",
    "        \n",
    "        # compute attention scores(affinities)\n",
    "        weights = query_vector @ key_vector.transpose(-2, -1) * head**-0.5\n",
    "        # mask values\n",
    "        weights = weights.masked_fill(self.tril == 0, -torch.inf)\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        out = weights @ value_vector\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71eea0ec-c3d9-4118-8fab-6cb65a8cb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a63d553-5dbf-47c5-bd62-8f344b90e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feed_Forward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),      # projection layer, residual connection\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = self.net(x)\n",
    "        return self.out"
   ]
  },
  {
   "attachments": {
    "c9823f2e-d827-4192-b329-972f2ff68104.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6a1d6deb-b53b-43fa-9888-3a6ba5fdef47",
   "metadata": {},
   "source": [
    "<h3>Layer Norm</h3><br>\n",
    "\n",
    "![Screenshot 2025-01-24 043310.png](attachment:c9823f2e-d827-4192-b329-972f2ff68104.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7bccc9-1e59-4264-81fc-3a33d8e29f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_mean = x.mean(dim=1, keepdim=True)\n",
    "        x_var = x.var(dim=1, keepdim=True)\n",
    "        x_hat = (x - x_mean) / (torch.sqrt(x_var + self.epsilon))\n",
    "        self.out = x_hat * self.gamma + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588be261-ef80-4fea-aee5-ef9951c7f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_block(nn.Module):\n",
    "    def __init__(self, n_embed, num_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // num_heads\n",
    "        self.attention = Multi_Head_Attention(num_heads, head_size)\n",
    "        self.feed_fwd = Feed_Forward(n_embed)\n",
    "        self.layer_norm1 = LayerNorm(n_embed)\n",
    "        self.layer_norm2 = LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention(self.layer_norm1(x))  # normalize inputs before sending to attention (not in paper)\n",
    "        x = self.feed_fwd(self.layer_norm2(x))    # normalize inputs before sending to MLP (not in paper)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4319bdb-fed8-4d33-824b-596ca662fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 64  # number of embeddings per vector\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embed)\n",
    "        self.transformer_layers = nn.Sequential(\n",
    "            Transformer_block(n_embed, 2),\n",
    "            Transformer_block(n_embed, 2),\n",
    "            nn.Dropout(0.2)\n",
    "            )\n",
    "        self.lang_model_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embeddings(idx) # shape = batch, context, n_embed\n",
    "        pos_emb = self.position_embedding(torch.arange(T)) # shape = T, n_embed\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.transformer_layers(x)\n",
    "        logits = self.lang_model_head(x) # shape = batch, context, vocab_size\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None       # while sampling\n",
    "        else:\n",
    "            batch, context, chara_probs = logits.shape\n",
    "            logits = logits.view(batch * context, chara_probs)\n",
    "            targets = targets.view(batch * context)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "        \n",
    "\n",
    "    def sample(self, idx, max_new_tokens):\n",
    "        # idx = context sequence\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond =  idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]  # focus on most recent char, shape = (batch, chara_probs=65)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # shape = (batch, context+1)\n",
    "            \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aee5be9-2d4d-4f92-9c65-e3ef425a9b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Trainable\n",
       "======================================================================\n",
       "BigramLanguageModel                           True\n",
       "├─Embedding: 1-1                              True\n",
       "├─Embedding: 1-2                              True\n",
       "├─Sequential: 1-3                             True\n",
       "│    └─Transformer_block: 2-1                 True\n",
       "│    │    └─LayerNorm: 3-1                    --\n",
       "│    │    └─Multi_Head_Attention: 3-2         True\n",
       "│    │    └─LayerNorm: 3-3                    --\n",
       "│    │    └─Feed_Forward: 3-4                 True\n",
       "│    └─Transformer_block: 2-2                 True\n",
       "│    │    └─LayerNorm: 3-5                    --\n",
       "│    │    └─Multi_Head_Attention: 3-6         True\n",
       "│    │    └─LayerNorm: 3-7                    --\n",
       "│    │    └─Feed_Forward: 3-8                 True\n",
       "│    └─Dropout: 2-3                           --\n",
       "│    └─Transformer_block: 2-4                 True\n",
       "│    │    └─LayerNorm: 3-9                    --\n",
       "│    │    └─Multi_Head_Attention: 3-10        True\n",
       "│    │    └─LayerNorm: 3-11                   --\n",
       "│    │    └─Feed_Forward: 3-12                True\n",
       "│    └─Dropout: 2-5                           --\n",
       "│    └─Transformer_block: 2-6                 True\n",
       "│    │    └─LayerNorm: 3-13                   --\n",
       "│    │    └─Multi_Head_Attention: 3-14        True\n",
       "│    │    └─LayerNorm: 3-15                   --\n",
       "│    │    └─Feed_Forward: 3-16                True\n",
       "│    └─LayerNorm: 2-7                         --\n",
       "│    └─Dropout: 2-8                           --\n",
       "├─Linear: 1-4                                 True\n",
       "======================================================================\n",
       "Total params: 197,436\n",
       "Trainable params: 197,436\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.99\n",
       "======================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 11.19\n",
       "Params size (MB): 0.79\n",
       "Estimated Total Size (MB): 11.98\n",
       "======================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model=BigramLanguageModel()\n",
    "summary(model,col_names=[\"trainable\"],input_data=x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e6d8064-ea9e-4bc2-a302-bd1a099c4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss using random samples in train and val set\n",
    "@torch.no_grad()\n",
    "def eval_loss(model, k_evals=200):\n",
    "    \"\"\"\n",
    "    \n",
    "    model: pass model\n",
    "    k_evals: number of samples i wanna evaluate. final loss = mean(losses)\n",
    "    .\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(k_evals)\n",
    "        for k in range(k_evals):\n",
    "            x, y = get_batch(split)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[k] = loss\n",
    "        out[split] = losses.mean()\n",
    "        \n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96d7fc2-3412-48f0-97cc-e392f0014350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8321975,  1.5294248, -0.0498837,  ...,  5.5097656, -3.4576488,\n",
       "           2.2139833],\n",
       "         [-3.8014920, -1.3549232, -3.6043174,  ...,  5.0738444, -0.5213884,\n",
       "           2.3523982],\n",
       "         [-1.7608663,  0.9405650,  0.3027689,  ...,  3.0518680,  1.1503776,\n",
       "           4.4665322],\n",
       "         ...,\n",
       "         [-0.3264793, -0.3572777, -0.6178424,  ...,  0.3021757, -0.3449218,\n",
       "           0.2438089],\n",
       "         [-0.4029801, -0.4703414, -0.0177950,  ..., -0.1167469, -0.4593930,\n",
       "          -0.2783322],\n",
       "         [-0.2493284, -0.1862219, -0.0907258,  ..., -0.1385843, -0.4597508,\n",
       "          -0.6296268]], grad_fn=<ViewBackward0>),\n",
       " tensor(4.2914295, grad_fn=<NllLossBackward0>),\n",
       " 106684)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BigramLanguageModel()\n",
    "logits, loss = m(x_batch, y_batch)\n",
    "param_count = sum(p.numel() for p in m.parameters())\n",
    "\n",
    "logits, loss, param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "428132df-a324-4467-a4b1-958a5780e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf8b62a6-9ee8-4857-b428-7234842a882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 \t | train_loss = 1.8804755210876465 \t| val_loss = 1.880314826965332\n",
      "iter 50 \t | train_loss = 1.8941513299942017 \t| val_loss = 1.8909765481948853\n",
      "iter 100 \t | train_loss = 1.8774014711380005 \t| val_loss = 1.878806710243225\n",
      "iter 150 \t | train_loss = 1.8589909076690674 \t| val_loss = 1.8590350151062012\n",
      "iter 200 \t | train_loss = 1.8615782260894775 \t| val_loss = 1.8597813844680786\n",
      "iter 250 \t | train_loss = 1.8253178596496582 \t| val_loss = 1.8259752988815308\n",
      "iter 300 \t | train_loss = 1.819313406944275 \t| val_loss = 1.8235676288604736\n",
      "iter 350 \t | train_loss = 1.8168867826461792 \t| val_loss = 1.8146950006484985\n",
      "iter 400 \t | train_loss = 1.7982231378555298 \t| val_loss = 1.7990293502807617\n",
      "iter 450 \t | train_loss = 1.7824065685272217 \t| val_loss = 1.781734824180603\n",
      "iter 499 \t | train_loss = 1.7713607549667358 \t| val_loss = 1.7716691493988037\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "iterations = 500\n",
    "\n",
    "for i in range(iterations):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%50 == 0 or i == iterations-1:\n",
    "        losses = eval_loss(m)\n",
    "        print(f\"iter {i} \\t | train_loss = {losses['train']} \\t| val_loss = {losses['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93c764-f79e-4e9f-a044-52b6c103d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "o\n",
      "v\n",
      "\n",
      "\n",
      "n?.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "K!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'r.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "o.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EN ,\n",
      "H  ?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tBn.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "?'sk lc navr?c n\n",
      "!\n",
      "on\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ph\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MaV ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O lsO yJs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Z l'u wyd! o .\n",
      "\n",
      "sd  ia,.\n",
      "\n",
      "\n",
      "\n",
      "ZeGa:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oww iok. e sJ\n",
      "Dnttatno snn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GENANRO:\n",
      "\n",
      "e cat:\n",
      "ciyir y  auum lan ad ld ' s u oncn.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wkiyesapo,\n",
      "\n",
      "\n",
      "\n",
      "ome telo,e ewsrt anaS il iusgp erPr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TCRSOO: IO:\n",
      "UJyo atet aitew aJ ou oa n's l\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Whio  ouisi'd nKaHOSecou:\n",
      "\n",
      "NO:\n",
      "s emo:\n",
      "\n",
      "\n",
      "\n",
      "Wethe t eseu t o sdTioy!\n",
      "rt  abl ayiro:\n",
      " uaO inttg o h ore\n",
      "\n",
      "\n",
      "Wfe oo n aimil' V b.\n",
      "\n",
      "HAOIUGIONADsd rse me k,\n",
      "\n",
      "Wh' wt wt p\n",
      "hevoteeno, ete au tTu, fiaf t tigo sar s:\n",
      "Thom ine,\n",
      "go!\n",
      "KRms g okicagucey G: ite yatg dathee'dep or tou tdu,lte,\n",
      "\n",
      "Nt lm, Tinome mongtory de you t, 'te'end an dou mb.\n",
      "BIings sanshoict. ogzip acJAnder,\n",
      " te IO:\n",
      "A: wotmes.\n",
      "A! pooanora s lgeN. fnmestGidBontond,\n",
      "\n",
      "qO meaco:Zcka s axneaNetive pdh\n",
      "Yaulnt LoApr,erg jeeyr m, wdoure teek adieT e soxnnaeigandhavedtt\n",
      "T! qu foxpomo:\n",
      "We,\n",
      "So. 'da waniis mo:\n",
      "WqreTathafetser, AR alne Wud y,\n",
      "posyeOruopowowond Gafs bnid\n",
      "\n",
      "Ha boredJevedea smeQq me Ou' sil dKSuresg, nansare loaken I t lofolaedof, bo MI has:\n",
      "Cicoudewitirelimid\n",
      "Ke,\n",
      "\n",
      "PATh ul nnsmsey wo arJUNSame,Perddev, hl. KIdetoras Pee Wicomeit wy'futang plEI.\n",
      "WhUH,\n",
      "TAmot me weiFp t'dveu y qucawn fFandsose mechur:\n",
      "WeeenO:\n",
      "Tenle. th\n",
      "tfe ssta\n",
      "boloy yUkN:\n",
      "Ha cfoule il! momash, Nwesumende!\n",
      "ORmud petHi'c s p tneiyo c. hame degons,Yehemdaver.\n",
      "IOret!\n",
      "O xail ant soKege oyhZZ thynr h u, ZamouloNuFeymenwecy melt mDrey ines ave d,\n",
      "TIpeset? kechaloherd motkeaL ? homKin ficayus?\n",
      "MrarJumZos\n",
      "TSPbe ewoMQdN:\n",
      "ANAserelleit! de gibe rind, hebkeratirama molse GomitERcnd wQmersfelskeus gilarewnd\n",
      "WI vehar:oleanolpret is sas f dlon teerbetligathicHe UhineBuAn!Tgr nono\n",
      "o wr PavoPI siresolcWghag ctorethseledo my lunjance MluTe aliso shigroD ts: om yretinunoryosche s halou imI'tonn sHoflLe l cetl bemVkeryaritto Ch\n",
      "TonVeldanem I ye mow, SBervess sshog k waneutrk igrivuistitho melre ft he honon yokULlldced, bll cesomitanody tavo dMo\n",
      "THD nuwasounetes!Us Afugrdfhincng fo,\n",
      "'e.XetheygUSele GmiHiweBecim I: nanncads\n",
      "Utowe, Ke wawrolGowondudatthany SteZ hyuriusendat fpAResuds!Hith\n",
      "!\n",
      "clhOYjy,?\n",
      "Mibo nge:ethoUxevameatsmat tV, adraMabter wemow o pd ansoy adJedpregangothiam\n",
      "Bvey? tsusrigoit chesokgph tJ ive feade:enr m, krayoIroch\n",
      "I'BaLTKE mEndelate per tuxttotor aglk. wire dglealn! wine Buy c!\n",
      "ASIshistholmaKvexe n ldd bell IJor noassE, nriverXEhid mmewecXd.\n",
      "AL Iroyqld fRe: o s oBeavelagundt m wd?kbolin pwer, BHeatindsyemead m k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_idx = torch.zeros((1, block_size), dtype=torch.long)\n",
    "\n",
    "#print(decode(m.sample(start_idx, max_new_tokens=500)[0].tolist()))\n",
    "print((decode(m.sample(start_idx, 2500)[0].tolist())[0])[block_size-1:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ede4575-6afa-4f3c-b07a-e9ce34a5a6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 128, 16]),\n",
       " tensor([[1.0000000, 0.0000000, 0.0000000,  ..., 0.0000000, 0.0000000,\n",
       "          0.0000000],\n",
       "         [0.3734562, 0.6265439, 0.0000000,  ..., 0.0000000, 0.0000000,\n",
       "          0.0000000],\n",
       "         [0.3717417, 0.2356559, 0.3926024,  ..., 0.0000000, 0.0000000,\n",
       "          0.0000000],\n",
       "         ...,\n",
       "         [0.0069616, 0.0063767, 0.0087181,  ..., 0.0080809, 0.0000000,\n",
       "          0.0000000],\n",
       "         [0.0064307, 0.0070403, 0.0101617,  ..., 0.0095384, 0.0061750,\n",
       "          0.0000000],\n",
       "         [0.0099340, 0.0091463, 0.0071976,  ..., 0.0076946, 0.0091697,\n",
       "          0.0078615]], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention\n",
    "head_size = 16\n",
    "\n",
    "x_test, y_test = get_batch('train')\n",
    "test= nn.Embedding(vocab_size, vocab_size)\n",
    "x_test = test(x_test)\n",
    "x_test.shape # batch=32, context=8, vocab=65\n",
    "\n",
    "key = nn.Linear(vocab_size, head_size, bias=False)\n",
    "query = nn.Linear(vocab_size, head_size, bias=False)\n",
    "value = nn.Linear(vocab_size, head_size, bias=False)\n",
    "key_vector = key(x_test)       # shape= batch, context, head_size\n",
    "query_vector = query(x_test)   # shape= batch, context, head_size\n",
    "value_vector = value(x_test)   # shape= batch, context, head_size     \n",
    "weights = query_vector @ key_vector.transpose(dim0=1, dim1=2) * head_size**-0.5\n",
    "\n",
    "\n",
    "# create mask as big as context\n",
    "mask = torch.tril(torch.ones(block_size, block_size))\n",
    "#weights = torch.zeros_like(mask)\n",
    "#print(weights.shape)\n",
    "weights = weights.masked_fill(mask==0, -torch.inf)   # nodes from future never talk to past\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "x_bow = weights @ value_vector\n",
    "x_bow.shape, weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66689852-6355-438b-9f75-4bc99fbfe648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [ 4,  1,  8,  0,  8,  5,  7,  8,  2,  5, 3, 4, 5, 6, 7, 10,  4,  0,  6,  0,  4,  0,  9,  3,  3, 10,  4,  7,  0,  6,  3,  8, 10,  9,  8,  1,  9,  8,  1,  7,  7,  8,  5,  2,  7,  8,  4,  7,  3,  4,  3,  0,  2,  5,  0, 10,  1,  6,  6,  4,  4,  5,  9,  6,  5,  9,  7,  4,  8,  4,  6,  4,  1,  0,  1, 10,  0,  3,  0,  7,  0,  6, 10,  9,  0,  5,  3,  5,  1,  1,  9, 10,  8,  4,  1,  4,  2,  0,  2,  5,  3,  4,  6,  1,  6,  9,  0,  5,  3,  8,  6,  2,  2,  4,  8,  8,  5,  5,  0,  1,  5,  3,  4,  7,  9,  8,  5,  1,  6,  7,  5,  1,  9,  0,  4,  2,  7,  7,  4,  4,  2,  9,  0,  0,  8,  4,  6,  6,  3,  9,  0,  4,  8,  5,  6,  2,  4,  2,  8,  5,  0,  6,  8,  6,  1,  3,  1, 10,  6,  3,  7,  0,  2,  9, 10,  5,  7,  0,  8, 10,  1,  4,  4,  1,  9,  3,  1,  4,  9,  0,  7,  6,  3, 10,  2, 10,  3,  1,  4,  7,  8,  4,  1,  1,  9,  4,  7,  4,  8,  5, 10,  2,  5,  4,  8,  5,  3,  6,  2,  6,  7,  5,  5,  0,  8,  5,  4,  9,  5,  0,  8,  1,  0,  6,  0,  2, 10,  5,  3,  2,  5,  0, 10, 10,  8,  1,  4, 10, 10,  3,  9,  4,  6,  5,  8,  6,  4,  6, 10,  4,  0,  1,  5,  2,  2,  6,  5,  4,  0,  4,  7,  4,  8,  6,  7,  2, 10,  5,  2,  3,  4,  4,  3,  4,  2,  7,  5,  6, 10,  7,  5,  1,  4,  1,  6,  7,  3, 10,  1,  8,  7,  3, 10,  1,  1,  3,  2,  2,  1,  3,  4,  5,  7,  1,  1,  9, 10,  5,  2,  3,  3,  0,  3,  1,  6,  1,  3,  3,  5,  7,  1,  7,  3,  7,  6,  6,  9,  3,  4,  7, 10,  3,  2,  5,  9,  9,  8,  1,  6,  9,  4,  9,  5,  7,  3,  6,  0, 10,  6,  5,  5,  6,  3, 10,  4,  8,  5,  0,  6,  7,  7,  5,  1,  1,  0,  7,  3,  4, 10, 10,  5,  2,  9,  1,  1,  5,  7,  2,  7,  0,  8,  9,  0,  0,  3,  8,  1,  5,  4,  1,  6,  4,  0,  4,  1,  5,  5,  4, 10,  2,  3,  1,  3,  9,  8,  1,  3,  4,  2,  8,  1,  5,  9,  5,  7,  4,  2,  9,  0,  8,  9,  6,  0,  0,  6,  8,  7,  0,  8,  4,  0,  9, 10,  3,  1,  8,  9,  2,  8,  4,  4,  8,  1,  2,  4,  5,  2,  7,  4,  9,  2,  2,  4,  0,  7,  7,  5,  2,  5,  7,  5,  6, 10,  1,  5,  6,  8,  0,  2,  4,  9,  0, 10,  5,  9,  5,  0,  4,  5,  4,  2,  8,  7,  5,  8,  2,  2,  5,  6,  0]\n",
    "context_len = 64\n",
    "len(test), context_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63da9c8a-b322-466d-a03f-f5edb6a87f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_datapoints = len(test)//context_len\n",
    "num_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59ee6681-a073-4997-b556-161cefa4ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0\t| [4, 1, 8, 0, 8, 5, 7, 8, 2, 5, 3, 4, 5, 6, 7, 10, 4, 0, 6, 0, 4, 0, 9, 3, 3, 10, 4, 7, 0, 6, 3, 8, 10, 9, 8, 1, 9, 8, 1, 7, 7, 8, 5, 2, 7, 8, 4, 7, 3, 4, 3, 0, 2, 5, 0, 10, 1, 6, 6, 4, 4, 5, 9, 6]\t| [1, 8, 0, 8, 5, 7, 8, 2, 5, 3, 4, 5, 6, 7, 10, 4, 0, 6, 0, 4, 0, 9, 3, 3, 10, 4, 7, 0, 6, 3, 8, 10, 9, 8, 1, 9, 8, 1, 7, 7, 8, 5, 2, 7, 8, 4, 7, 3, 4, 3, 0, 2, 5, 0, 10, 1, 6, 6, 4, 4, 5, 9, 6, 5]\n",
      "\n",
      "idx=1\t| [5, 9, 7, 4, 8, 4, 6, 4, 1, 0, 1, 10, 0, 3, 0, 7, 0, 6, 10, 9, 0, 5, 3, 5, 1, 1, 9, 10, 8, 4, 1, 4, 2, 0, 2, 5, 3, 4, 6, 1, 6, 9, 0, 5, 3, 8, 6, 2, 2, 4, 8, 8, 5, 5, 0, 1, 5, 3, 4, 7, 9, 8, 5, 1]\t| [9, 7, 4, 8, 4, 6, 4, 1, 0, 1, 10, 0, 3, 0, 7, 0, 6, 10, 9, 0, 5, 3, 5, 1, 1, 9, 10, 8, 4, 1, 4, 2, 0, 2, 5, 3, 4, 6, 1, 6, 9, 0, 5, 3, 8, 6, 2, 2, 4, 8, 8, 5, 5, 0, 1, 5, 3, 4, 7, 9, 8, 5, 1, 6]\n",
      "\n",
      "idx=2\t| [6, 7, 5, 1, 9, 0, 4, 2, 7, 7, 4, 4, 2, 9, 0, 0, 8, 4, 6, 6, 3, 9, 0, 4, 8, 5, 6, 2, 4, 2, 8, 5, 0, 6, 8, 6, 1, 3, 1, 10, 6, 3, 7, 0, 2, 9, 10, 5, 7, 0, 8, 10, 1, 4, 4, 1, 9, 3, 1, 4, 9, 0, 7, 6]\t| [7, 5, 1, 9, 0, 4, 2, 7, 7, 4, 4, 2, 9, 0, 0, 8, 4, 6, 6, 3, 9, 0, 4, 8, 5, 6, 2, 4, 2, 8, 5, 0, 6, 8, 6, 1, 3, 1, 10, 6, 3, 7, 0, 2, 9, 10, 5, 7, 0, 8, 10, 1, 4, 4, 1, 9, 3, 1, 4, 9, 0, 7, 6, 3]\n",
      "\n",
      "idx=3\t| [3, 10, 2, 10, 3, 1, 4, 7, 8, 4, 1, 1, 9, 4, 7, 4, 8, 5, 10, 2, 5, 4, 8, 5, 3, 6, 2, 6, 7, 5, 5, 0, 8, 5, 4, 9, 5, 0, 8, 1, 0, 6, 0, 2, 10, 5, 3, 2, 5, 0, 10, 10, 8, 1, 4, 10, 10, 3, 9, 4, 6, 5, 8, 6]\t| [10, 2, 10, 3, 1, 4, 7, 8, 4, 1, 1, 9, 4, 7, 4, 8, 5, 10, 2, 5, 4, 8, 5, 3, 6, 2, 6, 7, 5, 5, 0, 8, 5, 4, 9, 5, 0, 8, 1, 0, 6, 0, 2, 10, 5, 3, 2, 5, 0, 10, 10, 8, 1, 4, 10, 10, 3, 9, 4, 6, 5, 8, 6, 4]\n",
      "\n",
      "idx=4\t| [4, 6, 10, 4, 0, 1, 5, 2, 2, 6, 5, 4, 0, 4, 7, 4, 8, 6, 7, 2, 10, 5, 2, 3, 4, 4, 3, 4, 2, 7, 5, 6, 10, 7, 5, 1, 4, 1, 6, 7, 3, 10, 1, 8, 7, 3, 10, 1, 1, 3, 2, 2, 1, 3, 4, 5, 7, 1, 1, 9, 10, 5, 2, 3]\t| [6, 10, 4, 0, 1, 5, 2, 2, 6, 5, 4, 0, 4, 7, 4, 8, 6, 7, 2, 10, 5, 2, 3, 4, 4, 3, 4, 2, 7, 5, 6, 10, 7, 5, 1, 4, 1, 6, 7, 3, 10, 1, 8, 7, 3, 10, 1, 1, 3, 2, 2, 1, 3, 4, 5, 7, 1, 1, 9, 10, 5, 2, 3, 3]\n",
      "\n",
      "idx=5\t| [3, 0, 3, 1, 6, 1, 3, 3, 5, 7, 1, 7, 3, 7, 6, 6, 9, 3, 4, 7, 10, 3, 2, 5, 9, 9, 8, 1, 6, 9, 4, 9, 5, 7, 3, 6, 0, 10, 6, 5, 5, 6, 3, 10, 4, 8, 5, 0, 6, 7, 7, 5, 1, 1, 0, 7, 3, 4, 10, 10, 5, 2, 9, 1]\t| [0, 3, 1, 6, 1, 3, 3, 5, 7, 1, 7, 3, 7, 6, 6, 9, 3, 4, 7, 10, 3, 2, 5, 9, 9, 8, 1, 6, 9, 4, 9, 5, 7, 3, 6, 0, 10, 6, 5, 5, 6, 3, 10, 4, 8, 5, 0, 6, 7, 7, 5, 1, 1, 0, 7, 3, 4, 10, 10, 5, 2, 9, 1, 1]\n",
      "\n",
      "idx=6\t| [1, 5, 7, 2, 7, 0, 8, 9, 0, 0, 3, 8, 1, 5, 4, 1, 6, 4, 0, 4, 1, 5, 5, 4, 10, 2, 3, 1, 3, 9, 8, 1, 3, 4, 2, 8, 1, 5, 9, 5, 7, 4, 2, 9, 0, 8, 9, 6, 0, 0, 6, 8, 7, 0, 8, 4, 0, 9, 10, 3, 1, 8, 9, 2]\t| [5, 7, 2, 7, 0, 8, 9, 0, 0, 3, 8, 1, 5, 4, 1, 6, 4, 0, 4, 1, 5, 5, 4, 10, 2, 3, 1, 3, 9, 8, 1, 3, 4, 2, 8, 1, 5, 9, 5, 7, 4, 2, 9, 0, 8, 9, 6, 0, 0, 6, 8, 7, 0, 8, 4, 0, 9, 10, 3, 1, 8, 9, 2, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_datapoints):\n",
    "    start_idx = i * context_len\n",
    "    end_idx = start_idx + context_len\n",
    "    x = test[start_idx:end_idx]\n",
    "    y = test[start_idx+1 : end_idx+1]\n",
    "    print(f\"idx={i}\\t| {x}\\t| {y}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16050aa-c11f-42b5-8c12-03ef06fa1d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
